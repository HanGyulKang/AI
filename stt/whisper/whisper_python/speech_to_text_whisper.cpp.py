import os
import subprocess
import argparse
import tempfile
from pydub import AudioSegment
from datetime import datetime
import numpy as np
import webrtcvad
import sounddevice as sd
import soundfile as sf

def has_speech(audio_data, sample_rate=16000):
    """
    ìŒì„±ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    """
    vad = webrtcvad.Vad(2)  # ë¯¼ê°ë„ ì„¤ì • (0-3)
    
    # 30ms í”„ë ˆì„ìœ¼ë¡œ ë¶„í• 
    frame_duration = 30  # ms
    frame_size = int(sample_rate * frame_duration / 1000)
    
    has_speech_frames = 0
    total_frames = 0
    
    for i in range(0, len(audio_data) - frame_size, frame_size):
        frame = audio_data[i:i + frame_size]
        if len(frame) == frame_size:
            is_speech = vad.is_speech(frame.tobytes(), sample_rate)
            if is_speech:
                has_speech_frames += 1
            total_frames += 1
    
    # 50% ì´ìƒì˜ í”„ë ˆì„ì—ì„œ ìŒì„±ì´ ê°ì§€ë˜ë©´ True
    return (has_speech_frames / total_frames) > 0.5 if total_frames > 0 else False

def record_audio_with_vad(duration=5, sample_rate=16000):
    """
    ìŒì„± í™œë™ ê°ì§€ë¥¼ í¬í•¨í•œ ì˜¤ë””ì˜¤ ë…¹ìŒ
    """
    print(f"ğŸ¤ {duration}ì´ˆ ë™ì•ˆ ë…¹ìŒ ì¤‘... (ë§ì”€í•´ì£¼ì„¸ìš”)")
    
    audio_data = sd.rec(int(duration * sample_rate), 
                       samplerate=sample_rate, 
                       channels=1, 
                       dtype='int16')
    sd.wait()
    
    # ìŒì„± í™œë™ ê°ì§€
    if has_speech(audio_data, sample_rate):
        print("âœ… ìŒì„± ê°ì§€ë¨!")
        return audio_data
    else:
        print("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None

def record_audio(duration=5, sample_rate=16000):
    """
    ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•˜ëŠ” í•¨ìˆ˜ (sounddevice ì‚¬ìš©)
    
    Args:
        duration (int): ë…¹ìŒ ì‹œê°„ (ì´ˆ)
        sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
    
    Returns:
        numpy.ndarray: ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°
    """
    print(f"ğŸ¤ {duration}ì´ˆ ë™ì•ˆ ë…¹ìŒ ì¤‘... (ë§ì”€í•´ì£¼ì„¸ìš”)")
    
    # ì˜¤ë””ì˜¤ ë…¹ìŒ
    audio_data = sd.rec(int(duration * sample_rate), 
                       samplerate=sample_rate, 
                       channels=1, 
                       dtype='int16')
    sd.wait()  # ë…¹ìŒ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
    
    print("âœ… ë…¹ìŒ ì™„ë£Œ!")
    return audio_data

def save_audio_to_wav(audio_data, file_path, sample_rate=16000):
    """
    ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        audio_data (numpy.ndarray): ì˜¤ë””ì˜¤ ë°ì´í„°
        file_path (str): ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
    """
    sf.write(file_path, audio_data, sample_rate)

def process_audio_file(input_file_path, output_dir=None):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        input_file_path (str): ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ì…ë ¥ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬)
    """
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(input_file_path):
        print(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file_path}")
        return None
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if output_dir is None:
        output_dir = os.path.dirname(os.path.abspath(input_file_path))
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # whisper.cpp ê²½ë¡œ ì„¤ì •
    whisper_cli_path = os.path.join(current_dir, "..", "pyannote", "whisper.cpp_local", "whisper-cli")
    model_path = os.path.join(current_dir, "..", "pyannote", "whisper.cpp_local", "model", "ggml-large-v2-q8_0.bin")
    
    # whisper.cpp ì‹¤í–‰ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(whisper_cli_path):
        print(f"ì˜¤ë¥˜: whisper-clië¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {whisper_cli_path}")
        print("whisper.cppê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    
    # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(model_path):
        print(f"ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        print("whisper.cpp ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    
    try:
        print(f"ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {input_file_path}")
        
        # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
        print("ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì¤‘...")
        audio = AudioSegment.from_file(input_file_path)
        print(f"ì˜¤ë””ì˜¤ ì •ë³´ - ê¸¸ì´: {len(audio)}ms, ìƒ˜í”Œë§ ë ˆì´íŠ¸: {audio.frame_rate}Hz")
        
        # 2. ë…¸ì´ì¦ˆ ì œê±° (Low-pass filter 3000Hz)
        print("ë…¸ì´ì¦ˆ ì œê±° ì¤‘ (Low-pass filter 3000Hz)...")
        audio = audio.low_pass_filter(3000)
        print("ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ")
        
        # 3. ë³¼ë¥¨ ë†’ì´ê¸° (+5 dB)
        print("ë³¼ë¥¨ì„ 5dB ì¦í­ ì¤‘...")
        audio = audio + 5
        print("ë³¼ë¥¨ ì¦í­ ì™„ë£Œ")
        
        # 4. ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ë¥¼ ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥
        input_filename = os.path.splitext(os.path.basename(input_file_path))[0]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        temp_wav_file = os.path.join(output_dir, f"{input_filename}_processed_{timestamp}.wav")
        
        print(f"ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ ì¤‘: {temp_wav_file}")
        audio.export(temp_wav_file, format="wav")
        print("ì„ì‹œ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        
        # 5. whisper.cppë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
        print("whisper.cppë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
        whisper_cmd = [
            whisper_cli_path,
            "-l", "ko",
            "-m", model_path,
            temp_wav_file
        ]
        
        result = subprocess.run(whisper_cmd, 
                              capture_output=True, 
                              text=True, 
                              cwd=os.path.dirname(whisper_cli_path))
        
        if result.returncode == 0:
            transcribed_text = result.stdout.strip()
            
            # 6. ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
            output_text_file = os.path.join(output_dir, f"{input_filename}_transcript_{timestamp}.txt")
            
            with open(output_text_file, 'w', encoding='utf-8') as f:
                f.write(f"=== ì˜¤ë””ì˜¤ íŒŒì¼: {input_file_path} ===\n")
                f.write(f"=== ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n\n")
                f.write("=== ë³€í™˜ëœ í…ìŠ¤íŠ¸ ===\n")
                f.write(transcribed_text)
                f.write("\n")
            
            print(f"\n=== ë³€í™˜ ì™„ë£Œ ===")
            print(f"ì…ë ¥ íŒŒì¼: {input_file_path}")
            print(f"ì¶œë ¥ í…ìŠ¤íŠ¸ íŒŒì¼: {output_text_file}")
            print(f"ë³€í™˜ëœ í…ìŠ¤íŠ¸:\n{transcribed_text}")
            
            # 7. ì„ì‹œ WAV íŒŒì¼ ì‚­ì œ
            os.remove(temp_wav_file)
            print(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {temp_wav_file}")
            
            return output_text_file
            
        else:
            print(f"whisper.cpp ì‹¤í–‰ ì‹¤íŒ¨:")
            print(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {result.stderr}")
            return None
            
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def process_realtime_audio():
    """
    ì‹¤ì‹œê°„ ë§ˆì´í¬ ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ë³¼ë¥¨ ì„ê³„ê°’ ë‚®ì¶¤)
    """
    print("=== ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ëª¨ë“œ ===")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ë§ì”€í•˜ì„¸ìš”.")
    print("ë³¼ë¥¨ ì„ê³„ê°’: 100 (ì‘ì€ ì†Œë¦¬ë„ ì¸ì‹)")
    print()
    
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # whisper.cpp ê²½ë¡œ ì„¤ì •
    whisper_cli_path = os.path.join(current_dir, "..", "pyannote", "whisper.cpp_local", "whisper-cli")
    model_path = os.path.join(current_dir, "..", "pyannote", "whisper.cpp_local", "model", "ggml-large-v2-q8_0.bin")
    
    # whisper.cpp ì‹¤í–‰ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(whisper_cli_path):
        print(f"ì˜¤ë¥˜: whisper-clië¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {whisper_cli_path}")
        return
    
    # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(model_path):
        print(f"ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return
    
    try:
        while True:
            # ë…¹ìŒ ì‹œê°„ ì„¤ì •
            duration = 5  # 5ì´ˆì”© ë…¹ìŒ
            
            # ë³¼ë¥¨ ì²´í¬ë¥¼ í¬í•¨í•œ ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ ë…¹ìŒ (ì„ê³„ê°’: 100)
            audio_data = record_audio_with_volume_check(duration=duration, threshold=100)
            
            if audio_data is None:
                print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”...")
                continue
            
            # ì„ì‹œ WAV íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_wav_path = temp_file.name
            
            # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥
            save_audio_to_wav(audio_data, temp_wav_path)
            
            # pydubë¡œ ì˜¤ë””ì˜¤ ì²˜ë¦¬
            print("ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì¤‘...")
            audio = AudioSegment.from_wav(temp_wav_path)
            
            # ë…¸ì´ì¦ˆ ì œê±° (Low-pass filter 3000Hz)
            audio = audio.low_pass_filter(3000)
            
            # ë³¼ë¥¨ ë†’ì´ê¸° (+5 dB)
            audio = audio + 5
            
            # ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ë¥¼ ë‹¤ì‹œ ì €ì¥
            audio.export(temp_wav_path, format="wav")
            
            # whisper.cppë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
            print("í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
            whisper_cmd = [
                whisper_cli_path,
                "-l", "ko",
                "-m", model_path,
                temp_wav_path
            ]
            
            result = subprocess.run(whisper_cmd, 
                                  capture_output=True, 
                                  text=True, 
                                  cwd=os.path.dirname(whisper_cli_path))
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(temp_wav_path)
            
            if result.returncode == 0:
                transcribed_text = result.stdout.strip()
                if transcribed_text:
                    print(f"ğŸ¯ ì¸ì‹ ê²°ê³¼: {transcribed_text}")
                    
                    # ì¢…ë£Œ ëª…ë ¹ í™•ì¸
                    if transcribed_text.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'ë']:
                        print("ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        break
                else:
                    print("ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                print("âŒ í…ìŠ¤íŠ¸ ë³€í™˜ ì‹¤íŒ¨")
            
            print("-" * 50)
            
    except KeyboardInterrupt:
        print("\nì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

def is_audio_loud_enough(audio_data, threshold=100):  # 1000 â†’ 100ìœ¼ë¡œ ë‚®ì¶¤
    """
    ì˜¤ë””ì˜¤ ë³¼ë¥¨ì´ ì¶©ë¶„í•œì§€ í™•ì¸ (ì„ê³„ê°’ì„ ë‚®ì¶¤)
    
    Args:
        audio_data (numpy.ndarray): ì˜¤ë””ì˜¤ ë°ì´í„°
        threshold (int): ë³¼ë¥¨ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 100)
    
    Returns:
        bool: ë³¼ë¥¨ì´ ì¶©ë¶„í•œì§€ ì—¬ë¶€
    """
    rms = np.sqrt(np.mean(audio_data**2))
    print(f"í˜„ì¬ ë³¼ë¥¨ ë ˆë²¨: {rms:.2f} (ì„ê³„ê°’: {threshold})")
    return rms > threshold

def record_audio_with_volume_check(duration=5, sample_rate=16000, threshold=100):
    """
    ë³¼ë¥¨ ì²´í¬ë¥¼ í¬í•¨í•œ ì˜¤ë””ì˜¤ ë…¹ìŒ (ì„ê³„ê°’ì„ ë‚®ì¶¤)
    
    Args:
        duration (int): ë…¹ìŒ ì‹œê°„ (ì´ˆ)
        sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
        threshold (int): ë³¼ë¥¨ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 100)
    
    Returns:
        numpy.ndarray or None: ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„° ë˜ëŠ” None
    """
    print(f"ğŸ¤ {duration}ì´ˆ ë™ì•ˆ ë…¹ìŒ ì¤‘... (ë§ì”€í•´ì£¼ì„¸ìš”)")
    
    audio_data = sd.rec(int(duration * sample_rate), 
                       samplerate=sample_rate, 
                       channels=1, 
                       dtype='int16')
    sd.wait()
    
    if is_audio_loud_enough(audio_data, threshold):
        print("âœ… ì¶©ë¶„í•œ ë³¼ë¥¨ ê°ì§€ë¨!")
        return audio_data
    else:
        print("âš ï¸ ë³¼ë¥¨ì´ ë‚®ì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
        return audio_data  # None ëŒ€ì‹  audio_data ë°˜í™˜ (ê³„ì† ì§„í–‰)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='whisper.cppë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ í…ìŠ¤íŠ¸ ë³€í™˜')
    parser.add_argument('input_file', nargs='?', help='ë³€í™˜í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('-o', '--output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ì…ë ¥ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬)')
    parser.add_argument('--realtime', action='store_true', help='ì‹¤ì‹œê°„ ë§ˆì´í¬ ì…ë ¥ ëª¨ë“œ')
    parser.add_argument('--threshold', type=int, default=100, help='ë³¼ë¥¨ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 100)')
    
    args = parser.parse_args()
    
    # ì‹¤ì‹œê°„ ëª¨ë“œê°€ ìš”ì²­ëœ ê²½ìš°
    if args.realtime:
        process_realtime_audio()
        return
    
    # ì…ë ¥ íŒŒì¼ì´ ì œê³µëœ ê²½ìš° íŒŒì¼ ì²˜ë¦¬
    if args.input_file:
        result_file = process_audio_file(args.input_file, args.output)
        if result_file:
            print(f"\nâœ… ë³€í™˜ ì„±ê³µ! ê²°ê³¼ íŒŒì¼: {result_file}")
        else:
            print("\nâŒ ë³€í™˜ ì‹¤íŒ¨!")
        return
    
    # ëŒ€í™”í˜• ëª¨ë“œ
    print("=== whisper.cpp ì˜¤ë””ì˜¤ í…ìŠ¤íŠ¸ ë³€í™˜ í”„ë¡œê·¸ë¨ ===")
    print("1. íŒŒì¼ ë³€í™˜ ëª¨ë“œ")
    print("2. ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ëª¨ë“œ")
    print("3. ì¢…ë£Œ")
    print()
    
    while True:
        choice = input("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (1-3): ").strip()
        
        if choice == "1":
            # íŒŒì¼ ë³€í™˜ ëª¨ë“œ
            input_file = input("ë³€í™˜í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if input_file:
                output_dir = input("ì¶œë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì—”í„°ì‹œ ê¸°ë³¸ê°’): ").strip()
                if not output_dir:
                    output_dir = None
                
                result_file = process_audio_file(input_file, output_dir)
                
                if result_file:
                    print(f"\nâœ… ë³€í™˜ ì„±ê³µ! ê²°ê³¼ íŒŒì¼: {result_file}")
                else:
                    print("\nâŒ ë³€í™˜ ì‹¤íŒ¨!")
            break
            
        elif choice == "2":
            # ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ëª¨ë“œ
            process_realtime_audio()
            break
            
        elif choice == "3":
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        else:
            print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1, 2, ë˜ëŠ” 3ì„ ì…ë ¥í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()