# ğŸ¤ [Speech-to-Text with Faster Whisper](./speech_to_text_final.py)

**ê°œì„ ëœ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ** - ë…¸ì´ì¦ˆ ì œê±°, ìŒëŸ‰ ìµœì í™”, ì˜¤í”„ë¼ì¸ ì§€ì›

## ğŸ“‹ ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [ì£¼ìš” ê¸°ëŠ¥](#ì£¼ìš”-ê¸°ëŠ¥)
- [ì„¤ì¹˜ ë° ì„¤ì •](#ì„¤ì¹˜-ë°-ì„¤ì •)
- [ì‚¬ìš©ë²•](#ì‚¬ìš©ë²•)
- [ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­](#ê¸°ìˆ ì -ì„¸ë¶€ì‚¬í•­)
- [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
- [ì‹ ë¢°ë„ í•´ì„](#ì‹ ë¢°ë„-í•´ì„)
- [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

## ğŸ¯ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **faster-whisper**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê³ ì„±ëŠ¥ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ë…¸ì´ì¦ˆ ì œê±°ì™€ ìŒëŸ‰ ìµœì í™” ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.

### âœ¨ í•µì‹¬ íŠ¹ì§•

- ğŸš€ **faster-whisper large-v2 ëª¨ë¸** ì‚¬ìš©
-  **ì˜¤í”„ë¼ì¸ ì§€ì›** - ëª¨ë¸ ìºì‹±ìœ¼ë¡œ ì¸í„°ë„· ì—†ì´ ì‹¤í–‰
- ğŸµ **ë…¸ì´ì¦ˆ ì œê±°** - Low-pass filter (3000Hz) ì ìš©
-  **ìŒëŸ‰ ìµœì í™”** - ìë™ ì •ê·œí™” ë° ë³¼ë¥¨ ì¦í­

## ï¸ ì£¼ìš” ê¸°ëŠ¥

### 1. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (Audio Preprocessing)

```python
def preprocess_audio(audio):
    # ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜
    if audio.channels == 2:
        audio = audio.set_channels(1)
    
    # ìƒ˜í”Œë ˆì´íŠ¸ 16kHz ë³€í™˜
    if audio.frame_rate != 16000:
        audio = audio.set_frame_rate(16000)
    
    # ì˜¤ë””ì˜¤ ì •ê·œí™”
    audio = normalize(audio)
    
    # Low-pass filter (3000Hz) - ë…¸ì´ì¦ˆ ì œê±°
    audio = low_pass_filter(audio, 3000)
    
    # ìŒëŸ‰ 5dB ì¦ê°€
    audio = audio + 5
```

### 2. ëª¨ë¸ ê´€ë¦¬ (Model Management)
í•œ ë²ˆ ë‹¤ìš´ë°›ì€ ëª¨ë¸ì— ëŒ€í•´ì„œëŠ” ì¬ë‹¤ìš´ë¡œë“œë¥¼ ë°›ì§€ ì•Šê³  ìºì‹± ëœ íŒŒì¼ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
def get_whisper_model():
    # GPU/CPU ìë™ ê°ì§€
    device = "cuda" if torch.cuda.is_available() else "cpu"
    compute_type = "float16" if device == "cuda" else "int8"
    
    # ì˜¤í”„ë¼ì¸ ëª¨ë“œ ìš°ì„  ì‹œë„
    try:
        model = WhisperModel("large-v2", local_files_only=True)
    except:
        # ì˜¨ë¼ì¸ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ)
        model = WhisperModel("large-v2", local_files_only=False)
```

##  ì„¤ì¹˜ ë° ì„¤ì •

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install faster-whisper
pip install pydub
pip install torch
```

### 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ)

```python
from faster_whisper import WhisperModel

# ì¸í„°ë„· ì—°ê²° í•„ìš” (ìµœì´ˆ 1íšŒë§Œ)
model = WhisperModel("large-v2", device="cpu", compute_type="int8")
```

## ğŸš€ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from speech_to_text_final import convert_audio_to_text_improved

# ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
result = convert_audio_to_text_improved("path/to/audio.mp3")
print(result)
```

### ë°°ì¹˜ ì²˜ë¦¬

```python
from speech_to_text_final import process_multiple_files

# ì—¬ëŸ¬ íŒŒì¼ ì²˜ë¦¬
file_paths = ["file1.mp3", "file2.wav", "file3.m4a"]
results = process_multiple_files(file_paths)
```

### ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰

```bash
python speech_to_text_final.py
```

##  ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

### ìµœì í™”ëœ Whisper íŒŒë¼ë¯¸í„°

```python
segments, info = model.transcribe(
    audio_path,
    language="ko",
    
    # ì •í™•ë„ í–¥ìƒ
    beam_size=5,           # ë¹” ì„œì¹˜ í¬ê¸° ì¦ê°€
    best_of=5,             # ë” ë§ì€ í›„ë³´ ê²€í† 
    temperature=0.0,        # ê²°ì •ì  ê²°ê³¼ ìœ ì§€
    
    # ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤
    condition_on_previous_text=True,
    initial_prompt="",
    
    # VAD (Voice Activity Detection)
    vad_filter=True,
    vad_parameters=dict(
        min_silence_duration_ms=1000,  # 1ì´ˆ ë¬´ìŒ í—ˆìš©
        speech_pad_ms=300              # 0.3ì´ˆ íŒ¨ë”©
    ),
    
    # ì„ê³„ê°’ ì¡°ì •
    compression_ratio_threshold=2.4,   # ì••ì¶• ë¹„ìœ¨ ì„ê³„ê°’
    no_speech_threshold=0.3,           # ë¬´ìŒ ì„ê³„ê°’ (0.6 â†’ 0.3)
    
    # ë°˜ë³µ ì²˜ë¦¬
    repetition_penalty=0.8,            # ë°˜ë³µ íŒ¨ë„í‹° ì™„í™”
    length_penalty=1.0,                # ê¸¸ì´ íŒ¨ë„í‹° ìœ ì§€
    
    # ê¸°íƒ€ ì˜µì…˜
    word_timestamps=False,             # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ë¹„í™œì„±í™”
    suppress_tokens=[-1],              # EOT í† í° ì–µì œ
    without_timestamps=False,          # íƒ€ì„ìŠ¤íƒ¬í”„ ìœ ì§€
    max_initial_timestamp=1.0,         # ì´ˆê¸° íƒ€ì„ìŠ¤íƒ¬í”„ ìµœëŒ€ê°’
)
```

### ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

1. **ì±„ë„ ë³€í™˜**: ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ (ìŒì„± ì¸ì‹ì— ìµœì í™”)
2. **ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜**: 16kHz (Whisper ëª¨ë¸ í‘œì¤€)
3. **ì •ê·œí™”**: ë³¼ë¥¨ ë ˆë²¨ ìë™ ì¡°ì •
4. **ë…¸ì´ì¦ˆ ì œê±°**: Low-pass filter (3000Hz)
5. **ìŒëŸ‰ ì¦í­**: +5dB ì¦ê°€

## âš¡ ì„±ëŠ¥ ìµœì í™”

### 1. ëª¨ë¸ ì¬ì‚¬ìš©

```python
# ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ëª¨ë¸ ì¬ì‚¬ìš©
_whisper_model = None
_model_loaded = False

def get_whisper_model():
    global _whisper_model, _model_loaded
    if not _model_loaded:
        # ëª¨ë¸ ë¡œë”© ë¡œì§
        _model_loaded = True
    return _whisper_model
```

### 2. íŒŒì¼ í¬ê¸° ì œí•œ

- **ìµœëŒ€ ê¸¸ì´**: 30ë¶„
- **ìë™ ìë¥´ê¸°**: 30ë¶„ ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ ì˜ë¦¼

### 3. ì„ì‹œ íŒŒì¼ ê´€ë¦¬

```python
# ì„ì‹œ WAV íŒŒì¼ ìë™ ì •ë¦¬
temp_wav_path = "/tmp/temp_audio_optimized.wav"
try:
    # ì²˜ë¦¬ ë¡œì§
finally:
    if os.path.exists(temp_wav_path):
        os.remove(temp_wav_path)
```

##  ì‹ ë¢°ë„ í•´ì„ ê°€ì´ë“œ

### ì‹ ë¢°ë„ ì ìˆ˜ ë²”ìœ„

| ì‹ ë¢°ë„ ë²”ìœ„ | ì˜ë¯¸ | ê¶Œì¥ì‚¬í•­ | ì´ëª¨ì§€ |
|------------|------|----------|--------|
| -0.1 ~ 0.0 | ë§¤ìš° ë†’ìŒ | ê²°ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆìŒ | âœ… |
| -0.3 ~ -0.1 | ë†’ìŒ | ëŒ€ë¶€ë¶„ ì •í™•í•¨ | âœ… |
| -0.6 ~ -0.3 | ë³´í†µ | ê²€í†  ê¶Œì¥ | âš ï¸ |
| -1.0 ~ -0.6 | ë‚®ìŒ | ìˆ˜ë™ ê²€í†  í•„ìš” | âŒ |
| -1.0 ì´í•˜ | ë§¤ìš° ë‚®ìŒ | ì¬ë…¹ìŒ ë˜ëŠ” ë‹¤ë¥¸ ë°©ë²• ê³ ë ¤ |  |

### ì‹ ë¢°ë„ì— ì˜í–¥ì„ ì£¼ëŠ” ìš”ì†Œ

-  **ìŒì„± í’ˆì§ˆ**: ëª…í™•í•œ ë°œìŒ, ì ì ˆí•œ ë³¼ë¥¨
-  **ë…¹ìŒ í™˜ê²½**: ë°°ê²½ ë…¸ì´ì¦ˆ, ì—ì½”
- ï¸ **í™”ì íŠ¹ì„±**: ë°œìŒ, ì–µì–‘, ì†ë„
- ğŸ¼ **ìŒì•… ìš”ì†Œ**: ë°˜ë³µ êµ¬ê°„, ê²¹ì¹˜ëŠ” ìŒì„±

